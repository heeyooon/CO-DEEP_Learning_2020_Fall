{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import tqdm.notebook as tq\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = pd.read_csv('/content/drive/MyDrive/gradpaper/data/book_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Using BERT for Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence_transformers\n",
    "bert_model = SentenceTransformer('xlm-r-bert-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embedding_using_BERT(model, data_column):\n",
    "    embedding_feature = model.encode(data_column)\n",
    "    print(\">>> CHECK SHAPE: \", embedding_feature.shape)\n",
    "    \n",
    "    return embedding_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_embedd = word_embedding_using_BERT(bert_model, book['title'])\n",
    "genre_embedd = word_embedding_using_BERT(bert_model, book['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## page, year feature\n",
    "\n",
    "import math \n",
    "\n",
    "page_year = book[['page', 'pub_year']]\n",
    "\n",
    "def sqrt_pow(row):\n",
    "    row['page_sqrt'] = math.sqrt(float(row['page']))\n",
    "    row['page_pow'] = math.pow(row['page'], 2)\n",
    "    \n",
    "    row['year_sqrt'] = math.sqrt(float(row['year']))\n",
    "    row['year_pow'] = math.pow(row['page'], 2)\n",
    "    \n",
    "    return row\n",
    "\n",
    "page_year = page_year.progress_apply(lambda x : sqrt_pow(x), axis = 1)\n",
    "    \n",
    "# np.save('page_year_embed.npy', page_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# major embed\n",
    "\n",
    "student = pd.read_csv('../student_final.csv')\n",
    "major_list = sorted(student['college'].unique())\n",
    "\n",
    "major_embedd = word_embedding_using_BERT(bert_model, major_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## image embed\n",
    "from keras import models\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "def preprocessed(book_ids, img_path):\n",
    "    new_images = []\n",
    "    no_image_ids = []\n",
    "    \n",
    "    for i in tq.tqdm(range(len(book_ids))):\n",
    "        book_file = img_path + book_ids[i] + '.jpg'\n",
    "        \n",
    "        try:\n",
    "            image = load_img(book_file, target_size = (224, 224))\n",
    "            image = img_to_array(image)\n",
    "            image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "            image = preprocess_input(image)\n",
    "            new_images.append(image)\n",
    "            \n",
    "        except:\n",
    "            no_image_ids.append(book_file)\n",
    "            print(book_file, end = ' ')\n",
    "        \n",
    "    return new_images, no_image_ids\n",
    "\n",
    "def get_features(extractor, image_list):\n",
    "    img_features = extractor.predict(image_list[0], verbose=0)\n",
    "    \n",
    "    for i in tq.tqdm(range(1, len(image_list))):\n",
    "        features = extractor.predict(image_list[i], verbose=0)\n",
    "        img_features = np.append(img_features, features, axis = 0)\n",
    "    \n",
    "    return img_features\n",
    "\n",
    "\n",
    "def feature_extract_pipeline(extractor, img_path, book_ids):\n",
    "    preprocessed_images, no_images = preprocessed(book_ids, img_path)\n",
    "    image_features = get_features(extractor, preprocessed_images)\n",
    "    print(\"CHECK SHAPE: \", image_features.shape)\n",
    "    \n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "\n",
    "base_model = EfficientNetB0(weights='imagenet')\n",
    "model_eff = models.Model(inputs = base_model.input, outputs = base_model.get_layer('avg_pool').output)\n",
    "\n",
    "book_ids = book['book_id']\n",
    "image_path = '/content/drive/MyDrive/gradpaper/data/image/'\n",
    "\n",
    "image_features = feature_extract_pipeline(model_eff, image_path, book_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
