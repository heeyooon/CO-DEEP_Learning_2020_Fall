{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "## BEFORE YOU START... \n",
    "#1. install libraries\n",
    "#2. install chromedriver >> reference :: (https://beomi.github.io/gb-crawling/posts/2017-02-27-HowToMakeWebCrawler-With-Selenium.html)\n",
    "#3. make a new folder for save book covers\n",
    "\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "# !pip install selenium\n",
    "from selenium import webdriver\n",
    "import urllib\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_metadata(start, end, book_id_list, webdriver_path, image_save_path):\n",
    "    meta_df = pd.DataFrame()\n",
    "    \n",
    "    driver = webdriver.Chrome(webdriver_path) \n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    for i in range(start, end):\n",
    "        print(i, end = ' ')\n",
    "    \n",
    "        book_id = book_id_list[i]\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            time.sleep(1)\n",
    "            url = \"https://lib.skku.edu/#/search/total/si?all=1%7Ck%7Ca%7C{}\".format(book_id)\n",
    "            driver.get(url)\n",
    "    \n",
    "            result = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[2]/div/div[2]/div[2]/div[3]/div/ik-total-search[1]/div/div[2]/div/div[2]/ul/li[1]/a[2]')\n",
    "            result.click()\n",
    "    \n",
    "            driver.switch_to.window(driver.window_handles[1])\n",
    "    \n",
    "            #open the detailed info \n",
    "            try:\n",
    "                driver.find_element_by_css_selector('#btn-biblio-more-open').click()\n",
    "            except: \n",
    "                pass\n",
    "\n",
    "    \n",
    "            #image retreival \n",
    "            book_cover = driver.find_elements_by_css_selector('div.ikc-bookcover')\n",
    "            img_url = re.findall('(?<=src=\").+?(?=\")', book_cover[0].get_attribute('outerHTML'))[0]\n",
    "    \n",
    "            try:\n",
    "                img_name = image_save_path + '/' + book_id + '.jpg'\n",
    "                urllib.request.urlretrieve(img_url,img_name)\n",
    "                img = 'Y'\n",
    "        \n",
    "            except:\n",
    "                img = 'N'\n",
    "            \n",
    "  \n",
    "            ##book title \n",
    "            book_title = driver.find_element_by_css_selector('body > div.ikc-pyxis-wrap > div.ikc-container-wrap > div.ikc-container > div > div.ikc-main.kku-search > div.kku-main > div:nth-child(2) > div > div.ikc-search-detail-main > div > div.ikc-biblio-detail > div.ikc-biblio-info > ul > li:nth-child(1) > span').text\n",
    "            title = book_title.split('/')[0]\n",
    "            \n",
    "            pub_year = np.nan\n",
    "            page = np.nan\n",
    "            isbn = np.nan\n",
    "    \n",
    "            for i in range(3,9):\n",
    "                try:\n",
    "                    text = driver.find_element_by_css_selector('body > div.ikc-pyxis-wrap > div.ikc-container-wrap > div.ikc-container > div > div.ikc-main.kku-search > div.kku-main > div:nth-child(2) > div > div.ikc-search-detail-main > div > div.ikc-biblio-detail > div.ikc-biblio-info > ul > li:nth-child(' + str(i) + ') > label').text\n",
    "                    \n",
    "                    ##book pub year \n",
    "                    if text == '발행사항':\n",
    "                        book_pub= driver.find_element_by_css_selector('body > div.ikc-pyxis-wrap > div.ikc-container-wrap > div.ikc-container > div > div.ikc-main.kku-search > div.kku-main > div:nth-child(2) > div > div.ikc-search-detail-main > div > div.ikc-biblio-detail > div.ikc-biblio-info > ul > li:nth-child(' + str(i) + ') > span > span').text\n",
    "                        pubyear= book_pub.split(',')[-1]\n",
    "        \n",
    "                    ## book page \n",
    "                    elif text == '형태사항':\n",
    "                        book_page= driver.find_element_by_css_selector('body > div.ikc-pyxis-wrap > div.ikc-container-wrap > div.ikc-container > div > div.ikc-main.kku-search > div.kku-main > div:nth-child(2) > div > div.ikc-search-detail-main > div > div.ikc-biblio-detail > div.ikc-biblio-info > ul > li:nth-child(' + str(i) + ') > span > span').text\n",
    "                        page = book_page.split(' p.')[0]\n",
    "\n",
    "                    ## isbn\n",
    "                    elif text == 'ISBN':\n",
    "                        isbn = driver.find_element_by_css_selector('body > div.ikc-pyxis-wrap > div.ikc-container-wrap > div.ikc-container > div > div.ikc-main.kku-search > div.kku-main > div:nth-child(2) > div > div.ikc-search-detail-main > div > div.ikc-biblio-detail > div.ikc-biblio-info > ul > li:nth-child(' + str(i) + ') > span > span').text\n",
    "                        \n",
    "                    else: \n",
    "                        pass\n",
    "                    \n",
    "                except:\n",
    "                    break\n",
    "    \n",
    "            meta_df = meta_df.append({\"book_id\" : book_id, \"isbn\" : isbn, \"subject\" : title, \n",
    "                                      \"pub_year\" : pubyear, \"page\" : page, 'img' : img}, ignore_index = True)\n",
    "            \n",
    "            driver.close()\n",
    "            driver.switch_to_window(driver.window_handles[0])\n",
    "\n",
    "        \n",
    "        except:\n",
    "            meta_df = meta_df.append({\"book_id\" : book_id, \"isbn\" : 'notfound', 'subject' : 'notfound',\n",
    "                                      'pub_year' : 'notfound', 'page': 'notfound', 'img':'notfound'}, ignore_index = True)\n",
    "            \n",
    "    return meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(x):\n",
    "    try:\n",
    "        x = x.replace('&nbsp;', ' ')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try: \n",
    "        x = x.split('=')\n",
    "        return x[0]\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "\n",
    "def clean_page(x):\n",
    "    if x == \"notfound\":\n",
    "        return x\n",
    "    else: \n",
    "        try: \n",
    "            float(x)\n",
    "            return float(x)\n",
    "        \n",
    "        except: \n",
    "            if 'p' in x:\n",
    "                new_x = x.split('p')\n",
    "                try:\n",
    "                    return float(new_x[0].split(' ')[-1])\n",
    "                except:\n",
    "                    try:\n",
    "                        return float(new_x[1].split(' ')[0])\n",
    "                    except:\n",
    "                        try:\n",
    "                            return float(x.split(' p')[0].split(' ')[0])\n",
    "                        except:\n",
    "                            try: \n",
    "                                return float(x.split(' p')[0].split(' ')[1])\n",
    "                            except:\n",
    "                                return np.nan\n",
    "                \n",
    "        \n",
    "            elif ('cm' in x) or ('책' in x) or ('冊' in x) : \n",
    "                return np.nan\n",
    "            else:\n",
    "                if ',' in x:\n",
    "                    new_x = x.split(',')\n",
    "                    if 'p' in x:\n",
    "                        try:\n",
    "                            return float(x.split('p')[0])\n",
    "                        except:\n",
    "                            return np.nan\n",
    "                    \n",
    "                \n",
    "                    elif len(new_x) == 2:\n",
    "                        try:\n",
    "                            return float(new_x[0])\n",
    "                        except:\n",
    "                            try:\n",
    "                                return float(new_x[1])\n",
    "                            except:\n",
    "                                if '.' in new_x[1]:\n",
    "                                    try: \n",
    "                                        return float(new_x[1].split('.')[0])\n",
    "                                    except:\n",
    "                                        return np.nan                                \n",
    "                                elif ';' in new_x[1]:\n",
    "                                    try:\n",
    "                                        return float(new_x[1].split(';')[0])\n",
    "                                    except:\n",
    "                                        return np.nan\n",
    "                                else:\n",
    "                                    return np.nan\n",
    "               \n",
    "                    elif len(new_x) == 3:\n",
    "                        try: \n",
    "                            return float(new_x[1])\n",
    "                        except:\n",
    "                            try:\n",
    "                                return float(new_x[2])\n",
    "                            except:\n",
    "                                try:\n",
    "                                    return float(new_x[0])\n",
    "                                except:\n",
    "                                    return np.nan\n",
    "                \n",
    "               \n",
    "                elif ';' in x:\n",
    "                    try:\n",
    "                        return float(x.split(';')[-1])\n",
    "                    except:\n",
    "                        if 'p' in x:\n",
    "                            try:\n",
    "                                return float(x.split('p')[0])\n",
    "                            except:\n",
    "                                return np.nan\n",
    "                        else:\n",
    "                            return np.nan\n",
    "\n",
    "def clean_pub_year(x):\n",
    "    try: \n",
    "        return float(x)\n",
    "    \n",
    "    except:\n",
    "        r = list(x)        \n",
    "        s=''\n",
    "        for i in r:\n",
    "            if i.isdigit():\n",
    "                s+=str(i)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        #for years which have duration (first year)\n",
    "        s = s[:4]\n",
    "        \n",
    "        #for misinfo \n",
    "        if s == '':\n",
    "            if x == 'notfound':\n",
    "                return np.nan\n",
    "            else: \n",
    "                return np.nan\n",
    "        else:\n",
    "            return float(s)\n",
    "\n",
    "\n",
    "def clean_isbn(row):\n",
    "    x = row['isbn']\n",
    "    if pd.isna(x):\n",
    "        x, remark_x = np.nan, np.nan\n",
    "        \n",
    "    else:\n",
    "        if '(' in x:\n",
    "            new_x = x.split('(')\n",
    "            x = new_x[0]\n",
    "            remark_x = new_x[1].strip(')')\n",
    "    \n",
    "        elif '[' in x:\n",
    "            new_x = x.split('[')\n",
    "            x = new_x[0]\n",
    "            remark_x = new_x[1].strip(']')\n",
    "    \n",
    "        else:\n",
    "            remark_x = np.nan\n",
    "    \n",
    "    return [x, remark_x]\n",
    "\n",
    "\n",
    "def split_copy_n_vol(row):\n",
    "    x = row['book_ddc']\n",
    "    if pd.isna(x):\n",
    "        x, copy, vol = np.nan, np.nan, np.nan\n",
    "    else:\n",
    "        x = x.replace('[', '').replace(']', '')\n",
    "        try:\n",
    "            copy = x.split('c.')[1]\n",
    "            x = x.split('c.')[0]\n",
    "        except:\n",
    "            copy = np.nan\n",
    "        \n",
    "        try:\n",
    "            vol = x.split('v.')[1]\n",
    "            x = x.split('v.')[0]\n",
    "        except:\n",
    "            vol = np.nan\n",
    "    \n",
    "    return [x, copy, vol]\n",
    "\n",
    "def get_genre_from_ddc(row):\n",
    "    x = row['short_ddc']\n",
    "    \n",
    "    if x[0].isdigit():\n",
    "        gen_num = int(x[0])\n",
    "    else:\n",
    "        gen_num = int(x[2])\n",
    "        \n",
    "    genre_dicts = {0: 'Computer science, information and general works',\n",
    "                   1:'Philosophy and psychology',\n",
    "                   2: 'Religion', \n",
    "                   3: 'Social sciences',\n",
    "                   4: 'Language',\n",
    "                   5: 'Science',\n",
    "                   6:'Technology',\n",
    "                   7:'Arts and recreation',\n",
    "                   8:'Literature',\n",
    "                   9:'History and geography'}\n",
    "    \n",
    "    gen_words = genre_dicts[gen_num]\n",
    "    \n",
    "    return gen_words\n",
    "\n",
    "\n",
    "def make_unique_isbn(row):\n",
    "    if (pd.isna(row['isbn']) == True) or (pd.isna(row['volume']) == True):\n",
    "        return row['isbn']\n",
    "    else:\n",
    "        return str(row['isbn']) + '_' + str(row['volume'])\n",
    "    \n",
    "\n",
    "def clean_metadata(df, org_df, save_mode = False):\n",
    "    # cleaning subject, page, publish year\n",
    "    df['subject'] = df['subject'].apply(lambda x : clean_title(x))\n",
    "    df['page'] = df['page'].apply(lambda x : clean_page(x))\n",
    "    df['pub_year'] = df['pub_year'].apply(lambda x: clean_pub_year(x))\n",
    "    \n",
    "    print('>>> CLEANED Title, Page, Publish year')\n",
    "    \n",
    "    # cleaning isbn : separating remarks from isbn (13 digits)\n",
    "    temp1 = df.apply(lambda x : pd.Series(clean_isbn(x), index = ['isbn', 'isbn_remark']), axis = 1, result_type='expand')\n",
    "    \n",
    "    print('>>> CLEANED ISBN')\n",
    "    \n",
    "    # concatenating other features with isbn and isbn remarks\n",
    "    df = pd.concat([df[['book_id', 'img', 'page', 'pub_year', 'subject']], temp1], axis = 1)\n",
    "\n",
    "    # merge with book df and book metadata df\n",
    "    total_df = pd.merge(org_df, df[['book_id', 'img', 'page', 'pub_year', 'isbn', 'isbn_remark']], on = 'book_id', how = 'left')\n",
    "    \n",
    "    # separating ddc string as short ddc, copy(c.1) and volume(v.1)\n",
    "    temp2 = total_df.apply(lambda x : pd.Series(split_copy_n_vol(x), index = ['short_ddc', 'copy', 'volume']), axis = 1, result_type = 'expand')\n",
    "    \n",
    "    print('>>> SPLIT DDC into Short-ddc, Copy and Volume')\n",
    "    \n",
    "    # concatenating other features with temp2\n",
    "    total_df = pd.concat([total_df, temp2], axis = 1)\n",
    "    \n",
    "    # make unique isbn\n",
    "    total_df['unique_isbn'] = total_df.apply(lambda x: make_unique_isbn(x), axis = 1)\n",
    "    \n",
    "    # get genre from ddc\n",
    "    total_df['genre'] = total_df.progress_apply(lambda x: get_genre(x), axis = 1)\n",
    "    \n",
    "    print('>>> MADE Unique ISBN')\n",
    "    \n",
    "    # drop na\n",
    "    final_df = total_df[['book_id', 'title', 'short_ddc', 'unique_isbn', 'pub_year', 'page', 'img']].dropna()\n",
    "    final_df = final_df[final_df['img'] == 'Y']\n",
    "    \n",
    "    print(\">>> DROP NA and IMG == N\")\n",
    "    \n",
    "    # arrange\n",
    "    final_df.drop_duplicates('label', inplace=True)\n",
    "    final_df.sort_values('label', inplace=True)\n",
    "    final_df.set_index('label', inplace=True)\n",
    "    final_df.reset_index(inplace=True)\n",
    "    \n",
    "    if save_mode == True:\n",
    "        csv_save_name_total = 'book_data_total_' + str(start) + '_' + str(end) + '.csv'\n",
    "        csv_save_name_final = 'book_data_final_' + str(start) + '_' + str(end) + '.csv'\n",
    "        \n",
    "        total_df.to_csv(csv_save_name_total)\n",
    "        final_df.to_csv(csv_save_name_final)\n",
    "        \n",
    "    return total_df, final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = 0, 100\n",
    "webdriver_path = '../chromedriver'\n",
    "image_save_path = '../image'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    book_df = pd.read_csv('../book.csv', index_col = 0)\n",
    "    book_ids = book_df['book_id'].unique()\n",
    "    meta_df = get_book_metadata(start, end, book_ids, webdriver_path, image_save_path)\n",
    "    total_df, final_df = clean_metadata(meta_df, book_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
